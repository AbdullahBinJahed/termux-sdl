--- FFmpeg-n4.2.2/fftools/ffplay.c	2020-01-01 04:19:06.000000000 +0800
+++ termux-sdl/app/src/main/jni/ffplay/ffplay.c	2020-07-29 22:27:22.855245961 +0800
@@ -29,6 +29,8 @@
 #include <limits.h>
 #include <signal.h>
 #include <stdint.h>
+#include <stdbool.h>
+#include <string.h>
 
 #include "libavutil/avstring.h"
 #include "libavutil/eval.h"
@@ -53,11 +55,15 @@
 # include "libavfilter/buffersrc.h"
 #endif
 
-#include <SDL.h>
-#include <SDL_thread.h>
+#include "SDL.h"
+#include "SDL_thread.h"
+#include "SDL_ttf.h"
+#include "SDL2_gfxPrimitives.h"
 
 #include "cmdutils.h"
 
+#include "log.h"
+
 #include <assert.h>
 
 const char program_name[] = "ffplay";
@@ -310,10 +316,8 @@
 static AVInputFormat *file_iformat;
 static const char *input_filename;
 static const char *window_title;
-static int default_width  = 640;
-static int default_height = 480;
-static int screen_width  = 0;
-static int screen_height = 0;
+//static int default_width, default_height;
+static int screen_width, screen_height;
 static int screen_left = SDL_WINDOWPOS_CENTERED;
 static int screen_top = SDL_WINDOWPOS_CENTERED;
 static int audio_disable;
@@ -351,6 +355,10 @@
 static const char **vfilters_list = NULL;
 static int nb_vfilters = 0;
 static char *afilters = NULL;
+static char vfilters[20] = {""};
+// playback speed
+static float af_speed = 0.0f;
+static float vf_speed = 0.0f;
 #endif
 static int autorotate = 1;
 static int find_stream_info = 1;
@@ -368,6 +376,7 @@
 static SDL_Renderer *renderer;
 static SDL_RendererInfo renderer_info = {0};
 static SDL_AudioDeviceID audio_dev;
+static SDL_DisplayMode mode;
 
 static const struct TextureFormatEntry {
     enum AVPixelFormat format;
@@ -395,19 +404,45 @@
     { AV_PIX_FMT_NONE,           SDL_PIXELFORMAT_UNKNOWN },
 };
 
+
+// 这些方法实现在src/core/android/SDL_android.c
+
+// 设置亮度 
+extern void SDL_AndroidSetBrightness(int);
+// 获取亮度
+extern int SDL_AndroidGetBrightness(void);
+
+// 设置音量
+extern void SDL_AndroidSetVolume(int);
+// 获取音量
+extern int SDL_AndroidGetVolume(void);
+
+// ==========================================
+
+
 #if CONFIG_AVFILTER
-static int opt_add_vfilter(void *optctx, const char *opt, const char *arg)
-{
+static int opt_add_vfilter(void *optctx, const char *opt, const char *arg) {
     GROW_ARRAY(vfilters_list, nb_vfilters);
     vfilters_list[nb_vfilters - 1] = arg;
+
+    // 视频播放速度
+    if(arg != NULL && strcmp(vfilters, "") == 0) {
+        strncpy(vfilters, arg, strlen(arg));
+        if(strstr(vfilters, "setpts") != NULL) {
+            float vf_pts = 0;
+            sscanf(/*vfilters*/arg, "setpts=%f*PTS", &vf_pts);
+            vf_speed = 1.0f / vf_pts;
+            //LOGI(program_name, "vf_speed = %f\n", vf_speed);
+        }
+    }
+    //LOGI(program_name, "vfilters: %s\n", vfilters);
     return 0;
 }
 #endif
 
 static inline
 int cmp_audio_fmts(enum AVSampleFormat fmt1, int64_t channel_count1,
-                   enum AVSampleFormat fmt2, int64_t channel_count2)
-{
+                   enum AVSampleFormat fmt2, int64_t channel_count2) {
     /* If channel count == 1, planar and non-planar formats are the same */
     if (channel_count1 == 1 && channel_count2 == 1)
         return av_get_packed_sample_fmt(fmt1) != av_get_packed_sample_fmt(fmt2);
@@ -416,16 +451,14 @@
 }
 
 static inline
-int64_t get_valid_channel_layout(int64_t channel_layout, int channels)
-{
+int64_t get_valid_channel_layout(int64_t channel_layout, int channels) {
     if (channel_layout && av_get_channel_layout_nb_channels(channel_layout) == channels)
         return channel_layout;
     else
         return 0;
 }
 
-static int packet_queue_put_private(PacketQueue *q, AVPacket *pkt)
-{
+static int packet_queue_put_private(PacketQueue *q, AVPacket *pkt) {
     MyAVPacketList *pkt1;
 
     if (q->abort_request)
@@ -453,8 +486,7 @@
     return 0;
 }
 
-static int packet_queue_put(PacketQueue *q, AVPacket *pkt)
-{
+static int packet_queue_put(PacketQueue *q, AVPacket *pkt) {
     int ret;
 
     SDL_LockMutex(q->mutex);
@@ -467,8 +499,7 @@
     return ret;
 }
 
-static int packet_queue_put_nullpacket(PacketQueue *q, int stream_index)
-{
+static int packet_queue_put_nullpacket(PacketQueue *q, int stream_index) {
     AVPacket pkt1, *pkt = &pkt1;
     av_init_packet(pkt);
     pkt->data = NULL;
@@ -478,8 +509,7 @@
 }
 
 /* packet queue handling */
-static int packet_queue_init(PacketQueue *q)
-{
+static int packet_queue_init(PacketQueue *q) {
     memset(q, 0, sizeof(PacketQueue));
     q->mutex = SDL_CreateMutex();
     if (!q->mutex) {
@@ -495,8 +525,7 @@
     return 0;
 }
 
-static void packet_queue_flush(PacketQueue *q)
-{
+static void packet_queue_flush(PacketQueue *q) {
     MyAVPacketList *pkt, *pkt1;
 
     SDL_LockMutex(q->mutex);
@@ -513,15 +542,13 @@
     SDL_UnlockMutex(q->mutex);
 }
 
-static void packet_queue_destroy(PacketQueue *q)
-{
+static void packet_queue_destroy(PacketQueue *q) {
     packet_queue_flush(q);
     SDL_DestroyMutex(q->mutex);
     SDL_DestroyCond(q->cond);
 }
 
-static void packet_queue_abort(PacketQueue *q)
-{
+static void packet_queue_abort(PacketQueue *q) {
     SDL_LockMutex(q->mutex);
 
     q->abort_request = 1;
@@ -531,8 +558,7 @@
     SDL_UnlockMutex(q->mutex);
 }
 
-static void packet_queue_start(PacketQueue *q)
-{
+static void packet_queue_start(PacketQueue *q) {
     SDL_LockMutex(q->mutex);
     q->abort_request = 0;
     packet_queue_put_private(q, &flush_pkt);
@@ -540,8 +566,7 @@
 }
 
 /* return < 0 if aborted, 0 if no packet and > 0 if packet.  */
-static int packet_queue_get(PacketQueue *q, AVPacket *pkt, int block, int *serial)
-{
+static int packet_queue_get(PacketQueue *q, AVPacket *pkt, int block, int *serial) {
     MyAVPacketList *pkt1;
     int ret;
 
@@ -612,7 +637,9 @@
                     case AVMEDIA_TYPE_AUDIO:
                         ret = avcodec_receive_frame(d->avctx, frame);
                         if (ret >= 0) {
-                            AVRational tb = (AVRational){1, frame->sample_rate};
+                        AVRational tb = (AVRational) {
+                            1, frame->sample_rate
+                        };
                             if (frame->pts != AV_NOPTS_VALUE)
                                 frame->pts = av_rescale_q(frame->pts, d->avctx->pkt_timebase, tb);
                             else if (d->next_pts != AV_NOPTS_VALUE)
@@ -681,14 +708,12 @@
     avcodec_free_context(&d->avctx);
 }
 
-static void frame_queue_unref_item(Frame *vp)
-{
+static void frame_queue_unref_item(Frame *vp) {
     av_frame_unref(vp->frame);
     avsubtitle_free(&vp->sub);
 }
 
-static int frame_queue_init(FrameQueue *f, PacketQueue *pktq, int max_size, int keep_last)
-{
+static int frame_queue_init(FrameQueue *f, PacketQueue *pktq, int max_size, int keep_last) {
     int i;
     memset(f, 0, sizeof(FrameQueue));
     if (!(f->mutex = SDL_CreateMutex())) {
@@ -708,8 +733,7 @@
     return 0;
 }
 
-static void frame_queue_destory(FrameQueue *f)
-{
+static void frame_queue_destory(FrameQueue *f) {
     int i;
     for (i = 0; i < f->max_size; i++) {
         Frame *vp = &f->queue[i];
@@ -720,30 +744,25 @@
     SDL_DestroyCond(f->cond);
 }
 
-static void frame_queue_signal(FrameQueue *f)
-{
+static void frame_queue_signal(FrameQueue *f) {
     SDL_LockMutex(f->mutex);
     SDL_CondSignal(f->cond);
     SDL_UnlockMutex(f->mutex);
 }
 
-static Frame *frame_queue_peek(FrameQueue *f)
-{
+static Frame *frame_queue_peek(FrameQueue *f) {
     return &f->queue[(f->rindex + f->rindex_shown) % f->max_size];
 }
 
-static Frame *frame_queue_peek_next(FrameQueue *f)
-{
+static Frame *frame_queue_peek_next(FrameQueue *f) {
     return &f->queue[(f->rindex + f->rindex_shown + 1) % f->max_size];
 }
 
-static Frame *frame_queue_peek_last(FrameQueue *f)
-{
+static Frame *frame_queue_peek_last(FrameQueue *f) {
     return &f->queue[f->rindex];
 }
 
-static Frame *frame_queue_peek_writable(FrameQueue *f)
-{
+static Frame *frame_queue_peek_writable(FrameQueue *f) {
     /* wait until we have space to put a new frame */
     SDL_LockMutex(f->mutex);
     while (f->size >= f->max_size &&
@@ -758,8 +777,7 @@
     return &f->queue[f->windex];
 }
 
-static Frame *frame_queue_peek_readable(FrameQueue *f)
-{
+static Frame *frame_queue_peek_readable(FrameQueue *f) {
     /* wait until we have a readable a new frame */
     SDL_LockMutex(f->mutex);
     while (f->size - f->rindex_shown <= 0 &&
@@ -774,8 +792,7 @@
     return &f->queue[(f->rindex + f->rindex_shown) % f->max_size];
 }
 
-static void frame_queue_push(FrameQueue *f)
-{
+static void frame_queue_push(FrameQueue *f) {
     if (++f->windex == f->max_size)
         f->windex = 0;
     SDL_LockMutex(f->mutex);
@@ -784,8 +801,7 @@
     SDL_UnlockMutex(f->mutex);
 }
 
-static void frame_queue_next(FrameQueue *f)
-{
+static void frame_queue_next(FrameQueue *f) {
     if (f->keep_last && !f->rindex_shown) {
         f->rindex_shown = 1;
         return;
@@ -800,14 +816,12 @@
 }
 
 /* return the number of undisplayed frames in the queue */
-static int frame_queue_nb_remaining(FrameQueue *f)
-{
+static int frame_queue_nb_remaining(FrameQueue *f) {
     return f->size - f->rindex_shown;
 }
 
 /* return last shown position */
-static int64_t frame_queue_last_pos(FrameQueue *f)
-{
+static int64_t frame_queue_last_pos(FrameQueue *f) {
     Frame *fp = &f->queue[f->rindex];
     if (f->rindex_shown && fp->serial == f->pktq->serial)
         return fp->pos;
@@ -815,8 +829,7 @@
         return -1;
 }
 
-static void decoder_abort(Decoder *d, FrameQueue *fq)
-{
+static void decoder_abort(Decoder *d, FrameQueue *fq) {
     packet_queue_abort(d->queue);
     frame_queue_signal(fq);
     SDL_WaitThread(d->decoder_tid, NULL);
@@ -824,8 +837,7 @@
     packet_queue_flush(d->queue);
 }
 
-static inline void fill_rectangle(int x, int y, int w, int h)
-{
+static inline void fill_rectangle(int x, int y, int w, int h) {
     SDL_Rect rect;
     rect.x = x;
     rect.y = y;
@@ -835,8 +847,7 @@
         SDL_RenderFillRect(renderer, &rect);
 }
 
-static int realloc_texture(SDL_Texture **texture, Uint32 new_format, int new_width, int new_height, SDL_BlendMode blendmode, int init_texture)
-{
+static int realloc_texture(SDL_Texture **texture, Uint32 new_format, int new_width, int new_height, SDL_BlendMode blendmode, int init_texture) {
     Uint32 format;
     int access, w, h;
     if (!*texture || SDL_QueryTexture(*texture, &format, &access, &w, &h) < 0 || new_width != w || new_height != h || new_format != format) {
@@ -861,8 +872,7 @@
 
 static void calculate_display_rect(SDL_Rect *rect,
                                    int scr_xleft, int scr_ytop, int scr_width, int scr_height,
-                                   int pic_width, int pic_height, AVRational pic_sar)
-{
+                                   int pic_width, int pic_height, AVRational pic_sar) {
     AVRational aspect_ratio = pic_sar;
     int64_t width, height, x, y;
 
@@ -886,8 +896,7 @@
     rect->h = FFMAX((int)height, 1);
 }
 
-static void get_sdl_pix_fmt_and_blendmode(int format, Uint32 *sdl_pix_fmt, SDL_BlendMode *sdl_blendmode)
-{
+static void get_sdl_pix_fmt_and_blendmode(int format, Uint32 *sdl_pix_fmt, SDL_BlendMode *sdl_blendmode) {
     int i;
     *sdl_blendmode = SDL_BLENDMODE_NONE;
     *sdl_pix_fmt = SDL_PIXELFORMAT_UNKNOWN;
@@ -955,8 +964,7 @@
     return ret;
 }
 
-static void set_sdl_yuv_conversion_mode(AVFrame *frame)
-{
+static void set_sdl_yuv_conversion_mode(AVFrame *frame) {
 #if SDL_VERSION_ATLEAST(2,0,8)
     SDL_YUV_CONVERSION_MODE mode = SDL_YUV_CONVERSION_AUTOMATIC;
     if (frame && (frame->format == AV_PIX_FMT_YUV420P || frame->format == AV_PIX_FMT_YUYV422 || frame->format == AV_PIX_FMT_UYVY422)) {
@@ -971,8 +979,7 @@
 #endif
 }
 
-static void video_image_display(VideoState *is)
-{
+static void video_image_display(VideoState *is) {
     Frame *vp;
     Frame *sp = NULL;
     SDL_Rect rect;
@@ -1047,20 +1054,19 @@
             SDL_Rect target = {.x = rect.x + sub_rect->x * xratio,
                                .y = rect.y + sub_rect->y * yratio,
                                .w = sub_rect->w * xratio,
-                               .h = sub_rect->h * yratio};
+                               .h = sub_rect->h * yratio
+                              };
             SDL_RenderCopy(renderer, is->sub_texture, sub_rect, &target);
         }
 #endif
     }
 }
 
-static inline int compute_mod(int a, int b)
-{
+static inline int compute_mod(int a, int b) {
     return a < 0 ? a%b + b : a%b;
 }
 
-static void video_audio_display(VideoState *s)
-{
+static void video_audio_display(VideoState *s) {
     int i, i_start, x, y1, y, ys, delay, n, nb_display_channels;
     int ch, channels, h, h2;
     int64_t time_diff;
@@ -1201,8 +1207,7 @@
     }
 }
 
-static void stream_component_close(VideoState *is, int stream_index)
-{
+static void stream_component_close(VideoState *is, int stream_index) {
     AVFormatContext *ic = is->ic;
     AVCodecParameters *codecpar;
 
@@ -1258,8 +1263,7 @@
     }
 }
 
-static void stream_close(VideoState *is)
-{
+static void stream_close(VideoState *is) {
     /* XXX: use a special url_shutdown call to abort parse cleanly */
     is->abort_request = 1;
     SDL_WaitThread(is->read_tid, NULL);
@@ -1295,11 +1299,218 @@
     av_free(is);
 }
 
-static void do_exit(VideoState *is)
-{
+// ==================== draw progress =======================
+int start_x, start_y;
+int end_x, end_y;
+float curr_end_x;
+
+int line_width = 8;
+float progress = 0;
+// 拖动进度条标志
+bool is_seek_progress = false;
+
+static void draw_progress(SDL_Renderer *renderer) {
+    // 绘制进度条线
+    lineColor(renderer, start_x, start_y, end_x, end_y, 0xFFFFFFFF);
+    // 绘制当前进度 curr_end_x为当前播放进度条 结束的x坐标
+
+    curr_end_x = start_x + (end_x - start_x) * progress / 100;
+    if(curr_end_x > end_x)
+        curr_end_x = end_x;
+    thickLineRGBA(renderer, start_x, start_y,
+                  curr_end_x, end_y, line_width,
+                  0x66, 0xba, 0xff, 0xff);
+
+    // 绘制进度条小圆
+    filledCircleRGBA(renderer, curr_end_x, end_y, line_width * 2,
+                     0x66, 0xba, 0xff, 0xff);
+}
+
+// ==================== draw text =======================
+TTF_Font *font = NULL;
+SDL_Color text_color = { 0xff, 0xff, 0xff, 0};
+SDL_Rect text_rect;
+int font_size = 45;
+
+char total_duration[10] = {"00:00"};
+char curr_duration[10] = {"00:00"};
+
+char curr_volume[] = {"100"};
+char curr_bright[] = {"100"};
+
+
+int curr_time, total_time;
+float playback_speed = 1.0f;
+// 播放完成标志
+bool is_play_finished = false;
+// 音量改变标志
+bool is_changed_volume = false;
+// 亮度改变标志
+bool is_changed_bright = false;
+
+const char *font_path = "/system/fonts/DroidSans.ttf";
+
+// 文本位置
+enum text_position {
+    LEFT_TEXT, TOP_TEXT, RIGHT_TEXT, BOTTOM_TEXT, CENTER_TEXT, ANY_TEXT
+};
+
+// 初始化字体
+static void init_font(const char *font_path, int ptsize) {
+
+    /* Initialize the TTF library */
+    if(TTF_Init() < 0) {
+        LOGE(program_name, "Init TTF: %s\n", SDL_GetError());
+        return;
+    }
+
+    font = TTF_OpenFont(font_path, ptsize);
+
+    if(!font) {
+        LOGE(program_name, "Couldn't load TTF: %s\n", SDL_GetError());
+        return;
+    }
+
+    // 文本风格
+    TTF_SetFontStyle(font, TTF_STYLE_NORMAL);
+    TTF_SetFontHinting(font, TTF_HINTING_MONO);
+    TTF_SetFontOutline(font, 0);
+    TTF_SetFontKerning(font, 1);
+
+}
+
+// 绘制文本
+static void draw_text(SDL_Renderer *renderer, const char *text, int x, int y, int margin, int flag) {
+
+    // 消除锯齿感绘制文本
+    SDL_Surface *surface = TTF_RenderUTF8_Blended(font, text, text_color);
+    if(!surface) {
+        LOGE(program_name, "Surface: %s\n", SDL_GetError());
+    }
+
+    // 文本纹理
+    SDL_Texture *texture = SDL_CreateTextureFromSurface(renderer, surface);
+    if(!texture) {
+        LOGE(program_name, "Texture: %s\n", SDL_GetError());
+    }
+
+    // 文本绘制区域
+    text_rect.x = x; // 绘制文本开始x坐标
+    text_rect.y = y; // 绘制文本开始y坐标
+    text_rect.w = surface->w;
+    text_rect.h = surface->h;
+
+    // 如果是绘制右边的文本，文本的开始x坐标需要重新计算
+    // 如果不预先获得文本宽度，则绘制的文本可能显示不全
+    // x = screen_width - surface->w(文本宽度)
+    if(flag == RIGHT_TEXT) {
+        text_rect.x = screen_width - text_rect.w - margin;
+    } else if(flag == BOTTOM_TEXT) {
+        text_rect.y = screen_height - text_rect.h - margin;
+    } else if(flag == CENTER_TEXT) {
+        text_rect.x = screen_width / 2 - text_rect.w / 2;
+        text_rect.y = screen_height / 2 - text_rect.h / 2;
+    }
+
+    SDL_FreeSurface(surface);
+    SDL_RenderCopy(renderer, texture, NULL, &text_rect);
+
+    SDL_DestroyTexture(texture);
+
+}
+
+// 格式化时间
+static void format_time(int seconds, char *time) {
+
+    int hh = seconds / 3600;
+    int mm = (seconds % 3600) / 60;
+    int ss = seconds % 60;
+
+    if(hh > 0) {
+        sprintf(time, "%02d:%02d:%02d", hh, mm, ss);
+    } else {
+        sprintf(time, "%02d:%02d", mm, ss);
+    }
+}
+
+// 获取播放速度，用于设置时间速度
+static void set_playback_speed() {
+
+    if(vf_speed != 0 && af_speed != 0) {
+        playback_speed = vf_speed >= af_speed ? vf_speed : af_speed;
+    } else {
+
+        if(vf_speed != 0)
+            playback_speed = vf_speed;
+        else if(af_speed != 0)
+            playback_speed = af_speed;
+    }
+}
+
+// SDL_ttf绘制当前时间显示文本
+static void set_curr_duration(int seconds) {
+    // 当前显示的时间 = 时间 * 播放速度
+    if(seconds > total_time)
+        seconds = total_time;
+    format_time(seconds, curr_duration);
+    // 计算当前进度值百分比
+    curr_time = seconds;
+    progress = (curr_time * 100) / total_time;
+}
+
+// SDL_ttf绘制总共的时间显示文本
+static void set_total_duration(int seconds) {
+
+    //int tns  = is->ic->duration / 1000000LL;
+    total_time = seconds;
+    format_time(seconds, total_duration);
+}
+
+
+// 绘制函数
+static void draw(SDL_Renderer *renderer) {
+    // 绘制左边文本(当前时间)
+    draw_text(renderer, curr_duration, 10, screen_height - 200, 0, LEFT_TEXT);
+    // 在绘制左边的文本时，设置进度条开始坐标
+    start_x = text_rect.x + text_rect.w + 30;
+    start_y = text_rect.y + text_rect.h / 2;
+
+    // 绘制右边文本(总共时间)
+    draw_text(renderer, total_duration, screen_width, screen_height - 200, 10, RIGHT_TEXT);
+    // 在绘制右边的文本时，设置进度条结束坐标
+    end_x = text_rect.x - 30;
+    end_y = text_rect.y + text_rect.h / 2;
+
+    // 显示当前的音量或者亮度值
+    if(is_changed_volume || is_changed_bright) {
+        font_size = 200;
+        TTF_SetFontSize(font, font_size);
+        if(is_changed_volume) {
+            draw_text(renderer, curr_volume, screen_width / 2, screen_height / 2, 0, CENTER_TEXT);
+        } else {
+            draw_text(renderer, curr_bright, screen_width / 2, screen_height / 2, 0, CENTER_TEXT);
+        }
+
+        font_size = 45;
+        TTF_SetFontSize(font, font_size);
+    }
+    
+    // 绘制进度条
+    draw_progress(renderer);
+}
+
+
+
+static void do_exit(VideoState *is) {
     if (is) {
         stream_close(is);
     }
+
+    if(font) {
+        TTF_CloseFont(font);
+        TTF_Quit();
+    }
+
     if (renderer)
         SDL_DestroyRenderer(renderer);
     if (window)
@@ -1316,29 +1527,26 @@
     exit(0);
 }
 
-static void sigterm_handler(int sig)
-{
+static void sigterm_handler(int sig) {
     exit(123);
 }
 
-static void set_default_window_size(int width, int height, AVRational sar)
-{
+static void set_default_window_size(int width, int height, AVRational sar) {
     SDL_Rect rect;
-    int max_width  = screen_width  ? screen_width  : INT_MAX;
-    int max_height = screen_height ? screen_height : INT_MAX;
+    int max_width  = screen_width  ? screen_width  : mode.w/*INT_MAX*/;
+    int max_height = screen_height ? screen_height : mode.h/*INT_MAX*/;
     if (max_width == INT_MAX && max_height == INT_MAX)
         max_height = height;
     calculate_display_rect(&rect, 0, 0, max_width, max_height, width, height, sar);
-    default_width  = rect.w;
-    default_height = rect.h;
+    //default_width  = rect.w;
+    //default_height = rect.h;
 }
 
-static int video_open(VideoState *is)
-{
+static int video_open(VideoState *is) {
     int w,h;
 
-    w = screen_width ? screen_width : default_width;
-    h = screen_height ? screen_height : default_height;
+    w = screen_width ? screen_width : mode.w/*default_width*/;
+    h = screen_height ? screen_height : mode.h/*default_height*/;
 
     if (!window_title)
         window_title = input_filename;
@@ -1357,8 +1565,7 @@
 }
 
 /* display the current picture, if any */
-static void video_display(VideoState *is)
-{
+static void video_display(VideoState *is) {
     if (!is->width)
         video_open(is);
 
@@ -1368,51 +1575,52 @@
         video_audio_display(is);
     else if (is->video_st)
         video_image_display(is);
+
+    // 开始绘制
+    draw(renderer);
+    // 刷新显示视频
     SDL_RenderPresent(renderer);
 }
 
-static double get_clock(Clock *c)
-{
+static double get_clock(Clock *c) {
     if (*c->queue_serial != c->serial)
         return NAN;
     if (c->paused) {
         return c->pts;
     } else {
         double time = av_gettime_relative() / 1000000.0;
-        return c->pts_drift + time - (time - c->last_updated) * (1.0 - c->speed);
+        return c->pts_drift + time - (time - c->last_updated) * (1.0 - c->speed * 2);
     }
 }
 
-static void set_clock_at(Clock *c, double pts, int serial, double time)
-{
+static void set_clock_at(Clock *c, double pts, int serial, double time) {
+
     c->pts = pts;
     c->last_updated = time;
     c->pts_drift = c->pts - time;
     c->serial = serial;
 }
 
-static void set_clock(Clock *c, double pts, int serial)
-{
+static void set_clock(Clock *c, double pts, int serial) {
     double time = av_gettime_relative() / 1000000.0;
     set_clock_at(c, pts, serial, time);
 }
 
-static void set_clock_speed(Clock *c, double speed)
-{
+static void set_clock_speed(Clock *c, double speed) {
     set_clock(c, get_clock(c), c->serial);
     c->speed = speed;
+    LOGI(program_name, "speed = %f\n", speed);
+
 }
 
-static void init_clock(Clock *c, int *queue_serial)
-{
+static void init_clock(Clock *c, int *queue_serial) {
     c->speed = 1.0;
     c->paused = 0;
     c->queue_serial = queue_serial;
     set_clock(c, NAN, -1);
 }
 
-static void sync_clock_to_slave(Clock *c, Clock *slave)
-{
+static void sync_clock_to_slave(Clock *c, Clock *slave) {
     double clock = get_clock(c);
     double slave_clock = get_clock(slave);
     if (!isnan(slave_clock) && (isnan(clock) || fabs(clock - slave_clock) > AV_NOSYNC_THRESHOLD))
@@ -1436,8 +1644,7 @@
 }
 
 /* get the current master clock value */
-static double get_master_clock(VideoState *is)
-{
+static double get_master_clock(VideoState *is) {
     double val;
 
     switch (get_master_sync_type(is)) {
@@ -1469,8 +1677,7 @@
 }
 
 /* seek in the stream */
-static void stream_seek(VideoState *is, int64_t pos, int64_t rel, int seek_by_bytes)
-{
+static void stream_seek(VideoState *is, int64_t pos, int64_t rel, int seek_by_bytes) {
     if (!is->seek_req) {
         is->seek_pos = pos;
         is->seek_rel = rel;
@@ -1483,8 +1690,7 @@
 }
 
 /* pause or resume the video */
-static void stream_toggle_pause(VideoState *is)
-{
+static void stream_toggle_pause(VideoState *is) {
     if (is->paused) {
         is->frame_timer += av_gettime_relative() / 1000000.0 - is->vidclk.last_updated;
         if (is->read_pause_return != AVERROR(ENOSYS)) {
@@ -1496,34 +1702,29 @@
     is->paused = is->audclk.paused = is->vidclk.paused = is->extclk.paused = !is->paused;
 }
 
-static void toggle_pause(VideoState *is)
-{
+static void toggle_pause(VideoState *is) {
     stream_toggle_pause(is);
     is->step = 0;
 }
 
-static void toggle_mute(VideoState *is)
-{
+static void toggle_mute(VideoState *is) {
     is->muted = !is->muted;
 }
 
-static void update_volume(VideoState *is, int sign, double step)
-{
+static void update_volume(VideoState *is, int sign, double step) {
     double volume_level = is->audio_volume ? (20 * log(is->audio_volume / (double)SDL_MIX_MAXVOLUME) / log(10)) : -1000.0;
     int new_volume = lrint(SDL_MIX_MAXVOLUME * pow(10.0, (volume_level + sign * step) / 20.0));
     is->audio_volume = av_clip(is->audio_volume == new_volume ? (is->audio_volume + sign) : new_volume, 0, SDL_MIX_MAXVOLUME);
 }
 
-static void step_to_next_frame(VideoState *is)
-{
+static void step_to_next_frame(VideoState *is) {
     /* if the stream is paused unpause it, then step */
     if (is->paused)
         stream_toggle_pause(is);
     is->step = 1;
 }
 
-static double compute_target_delay(double delay, VideoState *is)
-{
+static double compute_target_delay(double delay, VideoState *is) {
     double sync_threshold, diff = 0;
 
     /* update delay to follow master synchronisation source */
@@ -1571,8 +1772,7 @@
 }
 
 /* called to display each frame */
-static void video_refresh(void *opaque, double *remaining_time)
-{
+static void video_refresh(void *opaque, double *remaining_time) {
     VideoState *is = opaque;
     double time;
 
@@ -1653,8 +1853,7 @@
 
                         if (sp->serial != is->subtitleq.serial
                                 || (is->vidclk.pts > (sp->pts + ((float) sp->sub.end_display_time / 1000)))
-                                || (sp2 && is->vidclk.pts > (sp2->pts + ((float) sp2->sub.start_display_time / 1000))))
-                        {
+                            || (sp2 && is->vidclk.pts > (sp2->pts + ((float) sp2->sub.start_display_time / 1000)))) {
                             if (sp->uploaded) {
                                 int i;
                                 for (i = 0; i < sp->sub.num_rects; i++) {
@@ -1712,6 +1911,14 @@
                 av_diff = get_master_clock(is) - get_clock(&is->vidclk);
             else if (is->audio_st)
                 av_diff = get_master_clock(is) - get_clock(&is->audclk);
+
+            // LOGI(program_name, "curr time: %7.2f\n", get_master_clock(is));
+            // 当前播放的时间 (clock * playback_speed)
+            // 当拖动进度条时，由calcu_curr_progress()方法设置当前时间，所有此处要判断is_seek_progress的值
+            if(!is_play_finished && !is_seek_progress)
+                set_curr_duration(((int)get_master_clock(is)) * playback_speed);
+
+
             av_log(NULL, AV_LOG_INFO,
                    "%7.2f %s:%7.3f fd=%4d aq=%5dKB vq=%5dKB sq=%5dB f=%"PRId64"/%"PRId64"   \r",
                    get_master_clock(is),
@@ -1729,8 +1936,7 @@
     }
 }
 
-static int queue_picture(VideoState *is, AVFrame *src_frame, double pts, double duration, int64_t pos, int serial)
-{
+static int queue_picture(VideoState *is, AVFrame *src_frame, double pts, double duration, int64_t pos, int serial) {
     Frame *vp;
 
 #if defined(DEBUG_SYNC)
@@ -1760,8 +1966,7 @@
     return 0;
 }
 
-static int get_video_frame(VideoState *is, AVFrame *frame)
-{
+static int get_video_frame(VideoState *is, AVFrame *frame) {
     int got_picture;
 
     if ((got_picture = decoder_decode_frame(&is->viddec, frame, NULL)) < 0)
@@ -1795,8 +2000,7 @@
 
 #if CONFIG_AVFILTER
 static int configure_filtergraph(AVFilterGraph *graph, const char *filtergraph,
-                                 AVFilterContext *source_ctx, AVFilterContext *sink_ctx)
-{
+                                 AVFilterContext *source_ctx, AVFilterContext *sink_ctx) {
     int ret, i;
     int nb_filters = graph->nb_filters;
     AVFilterInOut *outputs = NULL, *inputs = NULL;
@@ -1837,8 +2041,7 @@
     return ret;
 }
 
-static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const char *vfilters, AVFrame *frame)
-{
+static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const char *vfilters, AVFrame *frame) {
     enum AVPixelFormat pix_fmts[FF_ARRAY_ELEMS(sdl_texture_format_map)];
     char sws_flags_str[512] = "";
     char buffersrc_args[256];
@@ -1941,8 +2144,7 @@
     return ret;
 }
 
-static int configure_audio_filters(VideoState *is, const char *afilters, int force_output_format)
-{
+static int configure_audio_filters(VideoState *is, const char *afilters, int force_output_format) {
     static const enum AVSampleFormat sample_fmts[] = { AV_SAMPLE_FMT_S16, AV_SAMPLE_FMT_NONE };
     int sample_rates[2] = { 0, -1 };
     int64_t channel_layouts[2] = { 0, -1 };
@@ -2019,8 +2221,7 @@
 }
 #endif  /* CONFIG_AVFILTER */
 
-static int audio_thread(void *arg)
-{
+static int audio_thread(void *arg) {
     VideoState *is = arg;
     AVFrame *frame = av_frame_alloc();
     Frame *af;
@@ -2041,13 +2242,14 @@
             goto the_end;
 
         if (got_frame) {
-                tb = (AVRational){1, frame->sample_rate};
+            tb = (AVRational) {
+                1, frame->sample_rate
+            };
 
 #if CONFIG_AVFILTER
                 dec_channel_layout = get_valid_channel_layout(frame->channel_layout, frame->channels);
 
-                reconfigure =
-                    cmp_audio_fmts(is->audio_filter_src.fmt, is->audio_filter_src.channels,
+            reconfigure = cmp_audio_fmts(is->audio_filter_src.fmt, is->audio_filter_src.channels,
                                    frame->format, frame->channels)    ||
                     is->audio_filter_src.channel_layout != dec_channel_layout ||
                     is->audio_filter_src.freq           != frame->sample_rate ||
@@ -2068,6 +2270,16 @@
                     is->audio_filter_src.freq           = frame->sample_rate;
                     last_serial                         = is->auddec.pkt_serial;
 
+                // LOGI(program_name, "afilters: %s\n", afilters);
+                // 音频播放速度
+                if(afilters != NULL && strstr(afilters, "atempo") != NULL) {
+                    sscanf(afilters, "atempo=%f", &af_speed);
+                    LOGI(program_name, "af_speed: %f\n", af_speed);
+                }
+                // 设置播放速度
+                set_playback_speed();
+
+
                     if ((ret = configure_audio_filters(is, afilters, 1)) < 0)
                         goto the_end;
                 }
@@ -2084,7 +2296,9 @@
                 af->pts = (frame->pts == AV_NOPTS_VALUE) ? NAN : frame->pts * av_q2d(tb);
                 af->pos = frame->pkt_pos;
                 af->serial = is->auddec.pkt_serial;
-                af->duration = av_q2d((AVRational){frame->nb_samples, frame->sample_rate});
+                af->duration = av_q2d((AVRational) {
+                    frame->nb_samples, frame->sample_rate
+                });
 
                 av_frame_move_ref(af->frame, frame);
                 frame_queue_push(&is->sampq);
@@ -2106,8 +2320,7 @@
     return ret;
 }
 
-static int decoder_start(Decoder *d, int (*fn)(void *), const char *thread_name, void* arg)
-{
+static int decoder_start(Decoder *d, int (*fn)(void *), const char *thread_name, void *arg) {
     packet_queue_start(d->queue);
     d->decoder_tid = SDL_CreateThread(fn, thread_name, arg);
     if (!d->decoder_tid) {
@@ -2117,8 +2330,7 @@
     return 0;
 }
 
-static int video_thread(void *arg)
-{
+static int video_thread(void *arg) {
     VideoState *is = arg;
     AVFrame *frame = av_frame_alloc();
     double pts;
@@ -2203,7 +2415,9 @@
                 is->frame_last_filter_delay = 0;
             tb = av_buffersink_get_time_base(filt_out);
 #endif
-            duration = (frame_rate.num && frame_rate.den ? av_q2d((AVRational){frame_rate.den, frame_rate.num}) : 0);
+            duration = (frame_rate.num && frame_rate.den ? av_q2d((AVRational) {
+                frame_rate.den, frame_rate.num
+            }) : 0);
             pts = (frame->pts == AV_NOPTS_VALUE) ? NAN : frame->pts * av_q2d(tb);
             ret = queue_picture(is, frame, pts, duration, frame->pkt_pos, is->viddec.pkt_serial);
             av_frame_unref(frame);
@@ -2224,8 +2438,7 @@
     return 0;
 }
 
-static int subtitle_thread(void *arg)
-{
+static int subtitle_thread(void *arg) {
     VideoState *is = arg;
     Frame *sp;
     int got_subtitle;
@@ -2259,8 +2472,7 @@
 }
 
 /* copy samples for viewing in editor window */
-static void update_sample_display(VideoState *is, short *samples, int samples_size)
-{
+static void update_sample_display(VideoState *is, short *samples, int samples_size) {
     int size, len;
 
     size = samples_size / sizeof(short);
@@ -2279,8 +2491,7 @@
 
 /* return the wanted number of samples to get better sync if sync_type is video
  * or external master clock */
-static int synchronize_audio(VideoState *is, int nb_samples)
-{
+static int synchronize_audio(VideoState *is, int nb_samples) {
     int wanted_nb_samples = nb_samples;
 
     /* if not master, then we try to remove or add samples to correct the clock */
@@ -2327,8 +2538,7 @@
  * stored in is->audio_buf, with size in bytes given by the return
  * value.
  */
-static int audio_decode_frame(VideoState *is)
-{
+static int audio_resample_frame(VideoState *is) {
     int data_size, resampled_data_size;
     int64_t dec_channel_layout;
     av_unused double audio_clock0;
@@ -2440,8 +2650,7 @@
 }
 
 /* prepare a new audio buffer */
-static void sdl_audio_callback(void *opaque, Uint8 *stream, int len)
-{
+static void sdl_audio_callback(void *opaque, Uint8 *stream, int len) {
     VideoState *is = opaque;
     int audio_size, len1;
 
@@ -2449,7 +2658,7 @@
 
     while (len > 0) {
         if (is->audio_buf_index >= is->audio_buf_size) {
-           audio_size = audio_decode_frame(is);
+            audio_size = audio_resample_frame(is);
            if (audio_size < 0) {
                 /* if error, just output silence */
                is->audio_buf = NULL;
@@ -2483,8 +2692,7 @@
     }
 }
 
-static int audio_open(void *opaque, int64_t wanted_channel_layout, int wanted_nb_channels, int wanted_sample_rate, struct AudioParams *audio_hw_params)
-{
+static int audio_open(void *opaque, int64_t wanted_channel_layout, int wanted_nb_channels, int wanted_sample_rate, struct AudioParams *audio_hw_params) {
     SDL_AudioSpec wanted_spec, spec;
     const char *env;
     static const int next_nb_channels[] = {0, 0, 1, 6, 2, 6, 4, 6};
@@ -2557,8 +2765,7 @@
 }
 
 /* open a given stream. Return 0 if OK */
-static int stream_component_open(VideoState *is, int stream_index)
-{
+static int stream_component_open(VideoState *is, int stream_index) {
     AVFormatContext *ic = is->ic;
     AVCodecContext *avctx;
     AVCodec *codec;
@@ -2585,9 +2792,18 @@
     codec = avcodec_find_decoder(avctx->codec_id);
 
     switch(avctx->codec_type){
-        case AVMEDIA_TYPE_AUDIO   : is->last_audio_stream    = stream_index; forced_codec_name =    audio_codec_name; break;
-        case AVMEDIA_TYPE_SUBTITLE: is->last_subtitle_stream = stream_index; forced_codec_name = subtitle_codec_name; break;
-        case AVMEDIA_TYPE_VIDEO   : is->last_video_stream    = stream_index; forced_codec_name =    video_codec_name; break;
+    case AVMEDIA_TYPE_AUDIO   :
+        is->last_audio_stream    = stream_index;
+        forced_codec_name =    audio_codec_name;
+        break;
+    case AVMEDIA_TYPE_SUBTITLE:
+        is->last_subtitle_stream = stream_index;
+        forced_codec_name = subtitle_codec_name;
+        break;
+    case AVMEDIA_TYPE_VIDEO   :
+        is->last_video_stream    = stream_index;
+        forced_codec_name =    video_codec_name;
+        break;
     }
     if (forced_codec_name)
         codec = avcodec_find_decoder_by_name(forced_codec_name);
@@ -2709,8 +2925,7 @@
     return ret;
 }
 
-static int decode_interrupt_cb(void *ctx)
-{
+static int decode_interrupt_cb(void *ctx) {
     VideoState *is = ctx;
     return is->abort_request;
 }
@@ -2722,8 +2937,7 @@
            queue->nb_packets > MIN_FRAMES && (!queue->duration || av_q2d(st->time_base) * queue->duration > 1.0);
 }
 
-static int is_realtime(AVFormatContext *s)
-{
+static int is_realtime(AVFormatContext *s) {
     if(   !strcmp(s->iformat->name, "rtp")
        || !strcmp(s->iformat->name, "rtsp")
        || !strcmp(s->iformat->name, "sdp")
@@ -2739,8 +2953,7 @@
 }
 
 /* this thread gets the stream from the disk or the network */
-static int read_thread(void *arg)
-{
+static int read_thread(void *arg) {
     VideoState *is = arg;
     AVFormatContext *ic = NULL;
     int err, i, ret;
@@ -2816,6 +3029,9 @@
         }
     }
 
+    // 获取总共的时长
+    set_total_duration(is->ic->duration / 1000000LL);
+
     if (ic->pb)
         ic->pb->eof_reached = 0; // FIXME hack, ffplay maybe should not use avio_feof() to test for the end
 
@@ -2998,7 +3215,17 @@
         if (!is->paused &&
             (!is->audio_st || (is->auddec.finished == is->audioq.serial && frame_queue_nb_remaining(&is->sampq) == 0)) &&
             (!is->video_st || (is->viddec.finished == is->videoq.serial && frame_queue_nb_remaining(&is->pictq) == 0))) {
+
+            // 播放完成
+            is_play_finished = true;
+            progress = 100;
+            strcpy(curr_duration, total_duration);
+
             if (loop != 1 && (!loop || --loop)) {
+                // 循环播放，重新设置当前时间
+                is_play_finished = false;
+                progress = 0;
+                strcpy(curr_duration, "00:00");
                 stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);
             } else if (autoexit) {
                 ret = AVERROR_EOF;
@@ -3061,8 +3288,7 @@
     return 0;
 }
 
-static VideoState *stream_open(const char *filename, AVInputFormat *iformat)
-{
+static VideoState *stream_open(const char *filename, AVInputFormat *iformat) {
     VideoState *is;
 
     is = av_mallocz(sizeof(VideoState));
@@ -3116,8 +3342,7 @@
     return is;
 }
 
-static void stream_cycle_channel(VideoState *is, int codec_type)
-{
+static void stream_cycle_channel(VideoState *is, int codec_type) {
     AVFormatContext *ic = is->ic;
     int start_index, stream_index;
     int old_index;
@@ -3151,10 +3376,8 @@
     }
 
     for (;;) {
-        if (++stream_index >= nb_streams)
-        {
-            if (codec_type == AVMEDIA_TYPE_SUBTITLE)
-            {
+        if(++stream_index >= nb_streams) {
+            if(codec_type == AVMEDIA_TYPE_SUBTITLE) {
                 stream_index = -1;
                 is->last_subtitle_stream = -1;
                 goto the_end;
@@ -3195,14 +3418,12 @@
 }
 
 
-static void toggle_full_screen(VideoState *is)
-{
+static void toggle_full_screen(VideoState *is) {
     is_full_screen = !is_full_screen;
     SDL_SetWindowFullscreen(window, is_full_screen ? SDL_WINDOW_FULLSCREEN_DESKTOP : 0);
 }
 
-static void toggle_audio_display(VideoState *is)
-{
+static void toggle_audio_display(VideoState *is) {
     int next = is->show_mode;
     do {
         next = (next + 1) % SHOW_MODE_NB;
@@ -3230,8 +3451,7 @@
     }
 }
 
-static void seek_chapter(VideoState *is, int incr)
-{
+static void seek_chapter(VideoState *is, int incr) {
     int64_t pos = get_master_clock(is) * AV_TIME_BASE;
     int i;
 
@@ -3257,16 +3477,216 @@
                                  AV_TIME_BASE_Q), 0, 0);
 }
 
+
+
+// ============================================================
+
+// 滑动方向
+enum move_direction {
+    MOVE_LEFT, MOVE_UP, MOVE_RIGHT, MOVE_DOWN
+};
+
+float old_x, old_y;
+int volume_level = 0;
+int bright_level = 0;
+
+// 水平方向
+static int check_horizontal_direction(float touch_x) {
+    
+    if(touch_x < old_x) {
+        old_x = touch_x;
+        return MOVE_LEFT;
+    } else {
+        old_x = touch_x;
+        return MOVE_RIGHT;
+    }
+}
+
+// 垂直方向
+static int check_vertical_direction(float touch_y) {
+    
+    if(touch_y < old_y) {
+        old_y = touch_y;
+        return MOVE_UP;
+    } else {
+        old_y = touch_y;
+        return MOVE_DOWN;
+    }
+}
+
+// 设置亮度
+//SDL_SetWindowBrightness(window, value) not support android
+static void set_brightness_level(float touch_x, float touch_y) {
+    if(touch_x >= 0 && touch_x < screen_width / 2) {
+        is_changed_bright = true;
+#ifdef __ANDROID__
+        if(bright_level == 0)
+            bright_level = SDL_AndroidGetBrightness();
+#else
+        bright_level = SDL_GetWindowBrightness(window);
+#endif
+         if(check_vertical_direction(touch_y) == MOVE_UP) {
+            // 向上滑动增加亮度
+            ++bright_level;
+            if(bright_level > 100) bright_level = 100;
+        } else {
+            // 向下滑动减少亮度
+            --bright_level;
+            // 最低亮度5
+            if(bright_level < 5) bright_level = 5;
+        }
+        
+        sprintf(curr_bright, "%d", bright_level);
+        
+#ifdef __ANDROID__
+        // 调用android方法设置亮度
+        SDL_AndroidSetBrightness(bright_level);
+#else
+        // 调用SDL2方法设置亮度
+        if(SDL_SetWindowBrightness(window, bright_level) < 0) {
+            LOGE(program_name, "%s\n", SDL_GetError());
+        }
+#endif
+    }
+}
+
+
+// 设置音量
+static void set_volume_level(VideoState *stream, float touch_x, float touch_y) {
+    if(touch_x > screen_width / 2 && touch_x <= screen_width) {
+        is_changed_volume = true;
+        //int volume_level = av_clip(stream->audio_volume, 0, 100);
+        
+        // 当volume_level为0时，才调用SDL_AndroidGetVolume()方法
+        // SDL_AndroidGetVolume方法在[0..100]范围内，只会调用一次
+        if(volume_level == 0)
+            volume_level = SDL_AndroidGetVolume();
+        
+        if(check_vertical_direction(touch_y) == MOVE_UP) {
+            // 向上滑动增加音量
+            ++volume_level;
+            if(volume_level > 100) volume_level = 100;
+        } else {
+            // 向下滑动减少音量
+            --volume_level;
+            if(volume_level < 0) volume_level = 0;
+        }
+        
+        sprintf(curr_volume, "%d", volume_level);
+        
+        // stream->audio_volume为音频音量，不是系统音量
+        // 比如当前系统音量为50，那么audio_volume音量的范围就为[0..50]
+        // 也就是说audio_volume的最大值，为当前的系统音量
+        if(stream->audio_volume != startup_volume)
+            stream->audio_volume = volume_level;
+        
+        SDL_AndroidSetVolume(volume_level);
+    }
+}
+
+
+// 计算当前进度值
+static void calcu_curr_progress(float touch_x, float touch_y, double *frac) {
+    // 拖动进度条
+    if(touch_x >= start_x - 20 && touch_x <= end_x + 20
+            && touch_y >= start_y - 80 && touch_y <= end_y + 80) {
+        is_seek_progress = true;
+        is_play_finished = false;
+
+        curr_end_x = touch_x;
+        if(curr_end_x < start_x)
+            curr_end_x = start_x;
+        else if(curr_end_x > end_x)
+            curr_end_x = end_x;
+
+        *frac = ((curr_end_x - start_x)  / (end_x - start_x));
+        set_curr_duration((*frac) * total_time);
+    }
+}
+
+
+//typedef struct paramter {
+//    VideoState *stream;
+//    double frac;
+//} paramter;
+
+
+//static void seek_stream(void *data){
+//    struct paramter *params = (struct paramter*)data;
+//
+//    int64_t ts = params->frac * params->stream->ic->duration;
+//    if (params->stream->ic->start_time != AV_NOPTS_VALUE)
+//    ts += params->stream->ic->start_time;
+//    stream_seek(params->stream, ts, 0, 0);
+//}
+
+
+
 /* handle an event sent by the GUI */
-static void event_loop(VideoState *cur_stream)
-{
+static void event_loop(VideoState *cur_stream) {
     SDL_Event event;
     double incr, pos, frac;
+    float touch_x, touch_y;
+    Uint32 curr_timestamp = 0;
+    Uint32 last_timestamp = 0;
+    //SDL_Thread *seek_thread = NULL;
 
     for (;;) {
         double x;
         refresh_loop_wait_event(cur_stream, &event);
         switch (event.type) {
+        case SDL_FINGERDOWN: // 触摸按下
+
+            touch_x = event.tfinger.x * screen_width;
+            touch_y = event.tfinger.y * screen_height;
+            old_x = touch_x;
+            old_y = touch_y;
+            
+            curr_timestamp = event.tfinger.timestamp;
+            if(curr_timestamp - last_timestamp <= 300 && last_timestamp != 0) {
+                // 双击事件 
+                toggle_pause(cur_stream);
+                last_timestamp = 0;
+            } else {
+                // 单击事件
+                last_timestamp = curr_timestamp;
+                // 计算当前进度值
+                calcu_curr_progress(touch_x, touch_y, &frac);
+            }
+            break;
+        case SDL_FINGERMOTION: // 触摸移动
+            touch_x = event.tfinger.x * screen_width;
+            touch_y = event.tfinger.y * screen_height;
+            // 计算当前进度值
+            if(!is_changed_bright && !is_changed_volume)
+                calcu_curr_progress(touch_x, touch_y, &frac);
+
+            // 没有拖动进度条，才允许改变亮度和音量
+            if(!is_seek_progress) {
+                // 设置屏幕亮度
+                set_brightness_level(touch_x, touch_y);
+                // 设置音量
+                set_volume_level(cur_stream, touch_x, touch_y);
+            }
+            break;
+        case SDL_FINGERUP: // 触摸抬起
+
+            if(is_seek_progress) {
+                // 创建线程进行seek, 因为在触摸滑动(SDL_FINGERMOTION)中进行seek操作会卡帧
+                //struct paramter params = {cur_stream, frac};
+                //seek_thread = SDL_CreateThread(seek_stream, "seek thread", (void*)&params);
+
+                int64_t ts = frac * cur_stream->ic->duration;
+                if(cur_stream->ic->start_time != AV_NOPTS_VALUE)
+                    ts += cur_stream->ic->start_time;
+                stream_seek(cur_stream, ts, 0, 0);
+            }
+
+            is_seek_progress = false;
+            is_changed_volume = false;
+            is_changed_bright = false;
+
+            break;
         case SDL_KEYDOWN:
             if (exit_on_keydown || event.key.keysym.sym == SDLK_ESCAPE || event.key.keysym.sym == SDLK_q) {
                 do_exit(cur_stream);
@@ -3457,26 +3877,22 @@
     }
 }
 
-static int opt_frame_size(void *optctx, const char *opt, const char *arg)
-{
+static int opt_frame_size(void *optctx, const char *opt, const char *arg) {
     av_log(NULL, AV_LOG_WARNING, "Option -s is deprecated, use -video_size.\n");
     return opt_default(NULL, "video_size", arg);
 }
 
-static int opt_width(void *optctx, const char *opt, const char *arg)
-{
+static int opt_width(void *optctx, const char *opt, const char *arg) {
     screen_width = parse_number_or_die(opt, arg, OPT_INT64, 1, INT_MAX);
     return 0;
 }
 
-static int opt_height(void *optctx, const char *opt, const char *arg)
-{
+static int opt_height(void *optctx, const char *opt, const char *arg) {
     screen_height = parse_number_or_die(opt, arg, OPT_INT64, 1, INT_MAX);
     return 0;
 }
 
-static int opt_format(void *optctx, const char *opt, const char *arg)
-{
+static int opt_format(void *optctx, const char *opt, const char *arg) {
     file_iformat = av_find_input_format(arg);
     if (!file_iformat) {
         av_log(NULL, AV_LOG_FATAL, "Unknown input format: %s\n", arg);
@@ -3485,14 +3901,12 @@
     return 0;
 }
 
-static int opt_frame_pix_fmt(void *optctx, const char *opt, const char *arg)
-{
+static int opt_frame_pix_fmt(void *optctx, const char *opt, const char *arg) {
     av_log(NULL, AV_LOG_WARNING, "Option -pix_fmt is deprecated, use -pixel_format.\n");
     return opt_default(NULL, "pixel_format", arg);
 }
 
-static int opt_sync(void *optctx, const char *opt, const char *arg)
-{
+static int opt_sync(void *optctx, const char *opt, const char *arg) {
     if (!strcmp(arg, "audio"))
         av_sync_type = AV_SYNC_AUDIO_MASTER;
     else if (!strcmp(arg, "video"))
@@ -3506,20 +3920,17 @@
     return 0;
 }
 
-static int opt_seek(void *optctx, const char *opt, const char *arg)
-{
+static int opt_seek(void *optctx, const char *opt, const char *arg) {
     start_time = parse_time_or_die(opt, arg, 1);
     return 0;
 }
 
-static int opt_duration(void *optctx, const char *opt, const char *arg)
-{
+static int opt_duration(void *optctx, const char *opt, const char *arg) {
     duration = parse_time_or_die(opt, arg, 1);
     return 0;
 }
 
-static int opt_show_mode(void *optctx, const char *opt, const char *arg)
-{
+static int opt_show_mode(void *optctx, const char *opt, const char *arg) {
     show_mode = !strcmp(arg, "video") ? SHOW_MODE_VIDEO :
                 !strcmp(arg, "waves") ? SHOW_MODE_WAVES :
                 !strcmp(arg, "rdft" ) ? SHOW_MODE_RDFT  :
@@ -3527,8 +3938,7 @@
     return 0;
 }
 
-static void opt_input_file(void *optctx, const char *filename)
-{
+static void opt_input_file(void *optctx, const char *filename) {
     if (input_filename) {
         av_log(NULL, AV_LOG_FATAL,
                "Argument '%s' provided as input filename, but '%s' was already specified.\n",
@@ -3540,8 +3950,7 @@
     input_filename = filename;
 }
 
-static int opt_codec(void *optctx, const char *opt, const char *arg)
-{
+static int opt_codec(void *optctx, const char *opt, const char *arg) {
    const char *spec = strchr(opt, ':');
    if (!spec) {
        av_log(NULL, AV_LOG_ERROR,
@@ -3551,9 +3960,15 @@
    }
    spec++;
    switch (spec[0]) {
-   case 'a' :    audio_codec_name = arg; break;
-   case 's' : subtitle_codec_name = arg; break;
-   case 'v' :    video_codec_name = arg; break;
+    case 'a' :
+        audio_codec_name = arg;
+        break;
+    case 's' :
+        subtitle_codec_name = arg;
+        break;
+    case 'v' :
+        video_codec_name = arg;
+        break;
    default:
        av_log(NULL, AV_LOG_ERROR,
               "Invalid media specifier '%s' in option '%s'\n", spec, opt);
@@ -3614,21 +4029,21 @@
     { "scodec", HAS_ARG | OPT_STRING | OPT_EXPERT, { &subtitle_codec_name }, "force subtitle decoder", "decoder_name" },
     { "vcodec", HAS_ARG | OPT_STRING | OPT_EXPERT, {    &video_codec_name }, "force video decoder",    "decoder_name" },
     { "autorotate", OPT_BOOL, { &autorotate }, "automatically rotate video", "" },
-    { "find_stream_info", OPT_BOOL | OPT_INPUT | OPT_EXPERT, { &find_stream_info },
-        "read and decode the streams to fill missing information with heuristics" },
+    {
+        "find_stream_info", OPT_BOOL | OPT_INPUT | OPT_EXPERT, { &find_stream_info },
+        "read and decode the streams to fill missing information with heuristics"
+    },
     { "filter_threads", HAS_ARG | OPT_INT | OPT_EXPERT, { &filter_nbthreads }, "number of filter threads per graph" },
     { NULL, },
 };
 
-static void show_usage(void)
-{
+static void show_usage(void) {
     av_log(NULL, AV_LOG_INFO, "Simple media player\n");
     av_log(NULL, AV_LOG_INFO, "usage: %s [options] input_file\n", program_name);
     av_log(NULL, AV_LOG_INFO, "\n");
 }
 
-void show_help_default(const char *opt, const char *arg)
-{
+void show_help_default(const char *opt, const char *arg) {
     av_log_set_callback(log_callback_help);
     show_usage();
     show_help_options(options, "Main options:", 0, OPT_EXPERT, 0);
@@ -3663,8 +4078,7 @@
 }
 
 /* Called from the main */
-int main(int argc, char **argv)
-{
+int main(int argc, char **argv) {
     int flags;
     VideoState *is;
 
@@ -3734,7 +4148,15 @@
             flags |= SDL_WINDOW_BORDERLESS;
         else
             flags |= SDL_WINDOW_RESIZABLE;
-        window = SDL_CreateWindow(program_name, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, default_width, default_height, flags);
+
+        SDL_GetDesktopDisplayMode(0, &mode);
+        window = SDL_CreateWindow(input_filename,
+                                  SDL_WINDOWPOS_UNDEFINED,
+                                  SDL_WINDOWPOS_UNDEFINED,
+                                  /*default_width*/mode.w,
+                                  /*default_height*/mode.h,
+                                  flags | SDL_WINDOW_OPENGL);
+
         SDL_SetHint(SDL_HINT_RENDER_SCALE_QUALITY, "linear");
         if (window) {
             renderer = SDL_CreateRenderer(window, -1, SDL_RENDERER_ACCELERATED | SDL_RENDERER_PRESENTVSYNC);
@@ -3753,6 +4175,10 @@
         }
     }
 
+    // 初始化显示时间字体文件
+    init_font(font_path, font_size);
+    SDL_AndroidLogPrint(LOG_INFO, program_name, "hello ffplay %d\n", font_size);
+
     is = stream_open(input_filename, file_iformat);
     if (!is) {
         av_log(NULL, AV_LOG_FATAL, "Failed to initialize VideoState!\n");
